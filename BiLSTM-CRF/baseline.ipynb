{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  \\\nid                                                      \n0   交行14年用过，半年准备提额，却直接被降到1Ｋ，半年期间只T过一次三千，其它全部真实消费，第...   \n1                                 单标我有了，最近visa双标返现活动好   \n2                                         建设银行提额很慢的……   \n3                  我的怎么显示0.25费率，而且不管分多少期都一样费率，可惜只有69k   \n4                                            利率不错，可以撸   \n\n                                             BIO_anno  class  \\\nid                                                             \n0   [B-BANK, I-BANK, O, O, O, O, O, O, O, O, O, O,...      0   \n1   [B-PRODUCT, I-PRODUCT, O, O, O, O, O, O, B-PRO...      1   \n2   [B-BANK, I-BANK, I-BANK, I-BANK, B-COMMENTS_N,...      0   \n3   [O, O, O, O, O, O, O, O, O, O, B-COMMENTS_N, I...      2   \n4   [B-COMMENTS_N, I-COMMENTS_N, B-COMMENTS_ADJ, I...      1   \n\n                                        training_data  \nid                                                     \n0   ([交, 行, 1, 4, 年, 用, 过, ，, 半, 年, 准, 备, 提, 额, ，,...  \n1   ([单, 标, 我, 有, 了, ，, 最, 近, v, i, s, a, 双, 标, 返,...  \n2   ([建, 设, 银, 行, 提, 额, 很, 慢, 的, …, …], [B-BANK, I...  \n3   ([我, 的, 怎, 么, 显, 示, 0, ., 2, 5, 费, 率, ，, 而, 且,...  \n4   ([利, 率, 不, 错, ，, 可, 以, 撸], [B-COMMENTS_N, I-CO...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>BIO_anno</th>\n      <th>class</th>\n      <th>training_data</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>交行14年用过，半年准备提额，却直接被降到1Ｋ，半年期间只T过一次三千，其它全部真实消费，第...</td>\n      <td>[B-BANK, I-BANK, O, O, O, O, O, O, O, O, O, O,...</td>\n      <td>0</td>\n      <td>([交, 行, 1, 4, 年, 用, 过, ，, 半, 年, 准, 备, 提, 额, ，,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>单标我有了，最近visa双标返现活动好</td>\n      <td>[B-PRODUCT, I-PRODUCT, O, O, O, O, O, O, B-PRO...</td>\n      <td>1</td>\n      <td>([单, 标, 我, 有, 了, ，, 最, 近, v, i, s, a, 双, 标, 返,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>建设银行提额很慢的……</td>\n      <td>[B-BANK, I-BANK, I-BANK, I-BANK, B-COMMENTS_N,...</td>\n      <td>0</td>\n      <td>([建, 设, 银, 行, 提, 额, 很, 慢, 的, …, …], [B-BANK, I...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>我的怎么显示0.25费率，而且不管分多少期都一样费率，可惜只有69k</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, B-COMMENTS_N, I...</td>\n      <td>2</td>\n      <td>([我, 的, 怎, 么, 显, 示, 0, ., 2, 5, 费, 率, ，, 而, 且,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>利率不错，可以撸</td>\n      <td>[B-COMMENTS_N, I-COMMENTS_N, B-COMMENTS_ADJ, I...</td>\n      <td>1</td>\n      <td>([利, 率, 不, 错, ，, 可, 以, 撸], [B-COMMENTS_N, I-CO...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('train_data_public.csv', index_col='id')\n",
    "test_data = pd.read_csv('test_public.csv', index_col='id')\n",
    "\n",
    "train_data[\"BIO_anno\"] = train_data[\"BIO_anno\"].apply(lambda row: row.split(\" \"))\n",
    "train_data[\"training_data\"] = train_data.apply(lambda row: (list(row['text']), row['BIO_anno']),\n",
    "                                               axis=1)  ## axis=1 apply function to row, 0 to columns\n",
    "test_data[\"testing_data\"] = test_data.apply(lambda row: (list(row['text'])), axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "training_data_txt = []\n",
    "testing_data_txt = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    training_data_txt.append(train_data.iloc[i]['training_data'])\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    testing_data_txt.append(test_data.iloc[i]['testing_data'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]\n",
      "Torch version:  1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"Python version:  %s\" % (sys.version))\n",
    "print(\"Torch version:  %s\" % (torch.__version__))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x26c60d57ed0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "torch.manual_seed(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "training_data_txt = []\n",
    "testing_data_txt = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    training_data_txt.append(train_data.iloc[i]['training_data'])\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    testing_data_txt.append(test_data.iloc[i]['testing_data'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]\n",
      "Torch version:  1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"Python version:  %s\" % (sys.version))\n",
    "print(\"Torch version:  %s\" % (torch.__version__))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x26c60d57ed0>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "torch.manual_seed(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    # 返回vec的dim为1维度上的最大值索引\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim  # word embedding dim\n",
    "        self.hidden_dim = hidden_dim  # Bi-LSTM hidden dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # 将BiLSTM提取的特征向量映射到特征空间，即经过全连接得到发射分数\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # 转移矩阵的参数初始化，transitions[i,j]代表的是从第j个tag转移到第i个tag的转移分数\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # 初始化所有其他tag转移到START_TAG的分数非常小，即不可能由其他tag转移到START_TAG\n",
    "        # 初始化STOP_TAG转移到所有其他tag的分数非常小，即不可能由STOP_TAG转移到其他tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # 初始化LSTM的参数\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        # 通过Bi-LSTM提取特征\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # 计算给定tag序列的分数，即一条路径的分数\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            # 递推计算路径分数：转移分数 + 发射分数\n",
    "            score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # 通过前向算法递推计算\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # 初始化step 0即START位置的发射分数，START_TAG取0其他位置取-10000\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # 将初始化START位置为0的发射分数赋值给previous\n",
    "        previous = init_alphas\n",
    "\n",
    "        # 迭代整个句子\n",
    "        for obs in feats:\n",
    "            # 当前时间步的前向tensor\n",
    "            alphas_t = []\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # 取出当前tag的发射分数，与之前时间步的tag无关\n",
    "                emit_score = obs[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
    "                # 取出当前tag由之前tag转移过来的转移分数\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # 当前路径的分数：之前时间步分数 + 转移分数 + 发射分数\n",
    "                next_tag_var = previous + trans_score + emit_score\n",
    "                # 对当前分数取log-sum-exp\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            # 更新previous 递推计算下一个时间步\n",
    "            previous = torch.cat(alphas_t).view(1, -1)\n",
    "        # 考虑最终转移到STOP_TAG\n",
    "        terminal_var = previous + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        # 计算最终的分数\n",
    "        scores = log_sum_exp(terminal_var)\n",
    "        return scores\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # 初始化viterbi的previous变量\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        previous = init_vvars\n",
    "        for obs in feats:\n",
    "            # 保存当前时间步的回溯指针\n",
    "            bptrs_t = []\n",
    "            # 保存当前时间步的viterbi变量\n",
    "            viterbivars_t = []\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # 维特比算法记录最优路径时只考虑上一步的分数以及上一步tag转移到当前tag的转移分数\n",
    "                # 并不取决与当前tag的发射分数\n",
    "                next_tag_var = previous + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # 更新previous，加上当前tag的发射分数obs\n",
    "            previous = (torch.cat(viterbivars_t) + obs).view(1, -1)\n",
    "            # 回溯指针记录当前时间步各个tag来源前一步的tag\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        # 考虑转移到STOP_TAG的转移分数\n",
    "        terminal_var = previous + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # 通过回溯指针解码出最优路径\n",
    "        best_path = [best_tag_id]\n",
    "        # best_tag_id作为线头，反向遍历backpointers找到最优路径\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # 去除START_TAG\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        # CRF损失函数由两部分组成，真实路径的分数和所有路径的总分数。\n",
    "        # 真实路径的分数应该是所有路径中分数最高的。\n",
    "        # log真实路径的分数/log所有可能路径的分数，越大越好，构造crf loss函数取反，loss越小越好\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # 通过BiLSTM提取发射分数\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "        # 根据发射分数以及转移分数，通过viterbi解码找到一条最优路径\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 11\n",
    "HIDDEN_DIM = 6\n",
    "import time\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "# 将训练集汉字使用数字表示\n",
    "# 为了方便调试，先使用100条数据进行模型训练，选手可以采用全量数据进行训练\n",
    "training_data = training_data_txt\n",
    "word_to_ix = {}\n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "# 将测试集汉字使用数字表示\n",
    "testing_data = testing_data_txt\n",
    "for sentence in testing_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(125.1090), [6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 5, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 6, 0, 7, 4, 3])\n",
      "the 0  epoch\n",
      "Time Taken: 1 seconds\n",
      "the 1  epoch\n",
      "Time Taken: 290 seconds\n",
      "the 2  epoch\n",
      "Time Taken: 559 seconds\n",
      "the 3  epoch\n",
      "Time Taken: 834 seconds\n",
      "the 4  epoch\n",
      "Time Taken: 1131 seconds\n",
      "the 5  epoch\n",
      "Time Taken: 1434 seconds\n",
      "the 6  epoch\n",
      "Time Taken: 1737 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     23\u001B[0m targets \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([tag_to_ix[t] \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m tags], dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# 进行前向计算，取出crf loss\u001B[39;00m\n\u001B[1;32m---> 26\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mneg_log_likelihood\u001B[49m\u001B[43m(\u001B[49m\u001B[43msentence_in\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# 第四步，计算loss，梯度，通过optimier更新参数\u001B[39;00m\n\u001B[0;32m     29\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36mBiLSTM_CRF.neg_log_likelihood\u001B[1;34m(self, sentence, tags)\u001B[0m\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mneg_log_likelihood\u001B[39m(\u001B[38;5;28mself\u001B[39m, sentence, tags):\n\u001B[0;32m    127\u001B[0m     \u001B[38;5;66;03m# CRF损失函数由两部分组成，真实路径的分数和所有路径的总分数。\u001B[39;00m\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;66;03m# 真实路径的分数应该是所有路径中分数最高的。\u001B[39;00m\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;66;03m# log真实路径的分数/log所有可能路径的分数，越大越好，构造crf loss函数取反，loss越小越好\u001B[39;00m\n\u001B[0;32m    130\u001B[0m     feats \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_lstm_features(sentence)\n\u001B[1;32m--> 131\u001B[0m     forward_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_alg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeats\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    132\u001B[0m     gold_score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_score_sentence(feats, tags)\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_score \u001B[38;5;241m-\u001B[39m gold_score\n",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36mBiLSTM_CRF._forward_alg\u001B[1;34m(self, feats)\u001B[0m\n\u001B[0;32m     72\u001B[0m     next_tag_var \u001B[38;5;241m=\u001B[39m previous \u001B[38;5;241m+\u001B[39m trans_score \u001B[38;5;241m+\u001B[39m emit_score\n\u001B[0;32m     73\u001B[0m     \u001B[38;5;66;03m# 对当前分数取log-sum-exp\u001B[39;00m\n\u001B[1;32m---> 74\u001B[0m     alphas_t\u001B[38;5;241m.\u001B[39mappend(\u001B[43mlog_sum_exp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnext_tag_var\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     75\u001B[0m \u001B[38;5;66;03m# 更新previous 递推计算下一个时间步\u001B[39;00m\n\u001B[0;32m     76\u001B[0m previous \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(alphas_t)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36mlog_sum_exp\u001B[1;34m(vec)\u001B[0m\n\u001B[0;32m      9\u001B[0m     _, idx \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(vec, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m idx\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_sum_exp\u001B[39m(vec):\n\u001B[0;32m     14\u001B[0m     max_score \u001B[38;5;241m=\u001B[39m vec[\u001B[38;5;241m0\u001B[39m, argmax(vec)]\n\u001B[0;32m     15\u001B[0m     max_score_broadcast \u001B[38;5;241m=\u001B[39m max_score\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mexpand(\u001B[38;5;241m1\u001B[39m, vec\u001B[38;5;241m.\u001B[39msize()[\u001B[38;5;241m1\u001B[39m])\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "tag_to_ix = {\"O\": 0, \"B-BANK\": 1, \"I-BANK\": 2, \"B-PRODUCT\": 3, 'I-PRODUCT': 4,\n",
    "             'B-COMMENTS_N': 5, 'I-COMMENTS_N': 6, 'B-COMMENTS_ADJ': 7,\n",
    "             'I-COMMENTS_ADJ': 8, START_TAG: 9, STOP_TAG: 10}\n",
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "# 训练前检查模型预测结果\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "    print(model(precheck_sent))\n",
    "    a = model(precheck_sent)\n",
    "    a = pd.Series(a)\n",
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "for epoch in range(10):\n",
    "    print('the', epoch, ' epoch')\n",
    "    print(f'Time Taken: {round(time.time() - t)} seconds')\n",
    "    for sentence, tags in training_data:\n",
    "        # 第一步，pytorch梯度累积，需要清零梯度\n",
    "        model.zero_grad()\n",
    "\n",
    "        # 第二步，将输入转化为tensors\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "\n",
    "        # 进行前向计算，取出crf loss\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "        # 第四步，计算loss，梯度，通过optimier更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 训练结束查看模型预测结果，对比观察模型是否学到\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[3][0], word_to_ix)\n",
    "    print(model(precheck_sent))\n",
    "    a = model(precheck_sent)\n",
    "    a = pd.Series(a)\n",
    "    a.to_csv('test1.csv')\n",
    "# We got it!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2883it [00:11, 252.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        id                                           BIO_anno  class\n0        0  O O O O B-COMMENTS_N I-COMMENTS_N O O O O O O ...      2\n1        1  O O O O O O O O O B-BANK I-BANK O O O B-COMMEN...      2\n2        2  O O O O O O O O O B-PRODUCT I-PRODUCT B-COMMEN...      2\n3        3  O O O B-PRODUCT I-PRODUCT O O O O O O O O O O ...      2\n4        4                  O O O O O O B-BANK I-BANK O O O O      2\n...    ...                                                ...    ...\n2878  2878    O O O O O O O O O O O O B-PRODUCT I-PRODUCT O O      2\n2879  2879  O O O B-COMMENTS_ADJ I-COMMENTS_ADJ O O O O O ...      2\n2880  2880  O O O O O O O B-PRODUCT I-PRODUCT O O O O O O ...      2\n2881  2881  O B-PRODUCT I-PRODUCT I-PRODUCT B-COMMENTS_N I...      2\n2882  2882                                O O O O O O O O O O      2\n\n[2883 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>BIO_anno</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>O O O O B-COMMENTS_N I-COMMENTS_N O O O O O O ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>O O O O O O O O O B-BANK I-BANK O O O B-COMMEN...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>O O O O O O O O O B-PRODUCT I-PRODUCT B-COMMEN...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>O O O B-PRODUCT I-PRODUCT O O O O O O O O O O ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>O O O O O O B-BANK I-BANK O O O O</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2878</th>\n      <td>2878</td>\n      <td>O O O O O O O O O O O O B-PRODUCT I-PRODUCT O O</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2879</th>\n      <td>2879</td>\n      <td>O O O B-COMMENTS_ADJ I-COMMENTS_ADJ O O O O O ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2880</th>\n      <td>2880</td>\n      <td>O O O O O O O B-PRODUCT I-PRODUCT O O O O O O ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2881</th>\n      <td>2881</td>\n      <td>O B-PRODUCT I-PRODUCT I-PRODUCT B-COMMENTS_N I...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2882</th>\n      <td>2882</td>\n      <td>O O O O O O O O O O</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>2883 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "result = pd.DataFrame(columns=['id', 'BIO_anno', 'class'])\n",
    "result['id'] = test_data.index\n",
    "ix_to_tag = {value: key for key, value in tag_to_ix.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    #for i in range(len(test_data)):\n",
    "    for index, row in tqdm(test_data.iterrows()):\n",
    "        id = row.index\n",
    "        text = row['text']\n",
    "        # 预测 训练集第i条数据\n",
    "        #precheck_sent = prepare_sequence(test_data.loc[i, 'text'], word_to_ix)\n",
    "        precheck_sent = prepare_sequence(text, word_to_ix)\n",
    "        #print(precheck_sent)\n",
    "        a = model(precheck_sent)\n",
    "        a2 = ' '.join(ix_to_tag[x] for x in a[1])\n",
    "        result.loc[index, 'BIO_anno'] = a2\n",
    "result['class'] = 2\n",
    "result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-chinese/resolve/main/tokenizer_config.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSSLEOFError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:700\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    699\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_new_proxy_conn \u001B[38;5;129;01mand\u001B[39;00m http_tunnel_required:\n\u001B[1;32m--> 700\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_proxy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:996\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._prepare_proxy\u001B[1;34m(self, conn)\u001B[0m\n\u001B[0;32m    994\u001B[0m     conn\u001B[38;5;241m.\u001B[39mtls_in_tls_required \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 996\u001B[0m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\urllib3\\connection.py:414\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    412\u001B[0m     context\u001B[38;5;241m.\u001B[39mload_default_certs()\n\u001B[1;32m--> 414\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[43mssl_wrap_socket\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeyfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcertfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcert_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    418\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_password\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_password\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_certs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_certs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    421\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[43m    \u001B[49m\u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    424\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtls_in_tls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtls_in_tls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    425\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;66;03m# If we're using all defaults and the connection\u001B[39;00m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001B[39;00m\n\u001B[0;32m    429\u001B[0m \u001B[38;5;66;03m# for the host.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py:449\u001B[0m, in \u001B[0;36mssl_wrap_socket\u001B[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m send_sni:\n\u001B[1;32m--> 449\u001B[0m     ssl_sock \u001B[38;5;241m=\u001B[39m \u001B[43m_ssl_wrap_socket_impl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtls_in_tls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\urllib3\\util\\ssl_.py:493\u001B[0m, in \u001B[0;36m_ssl_wrap_socket_impl\u001B[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001B[0m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m server_hostname:\n\u001B[1;32m--> 493\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrap_socket\u001B[49m\u001B[43m(\u001B[49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Python310\\lib\\ssl.py:513\u001B[0m, in \u001B[0;36mSSLContext.wrap_socket\u001B[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001B[0m\n\u001B[0;32m    507\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrap_socket\u001B[39m(\u001B[38;5;28mself\u001B[39m, sock, server_side\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    508\u001B[0m                 do_handshake_on_connect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    509\u001B[0m                 suppress_ragged_eofs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    510\u001B[0m                 server_hostname\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, session\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    511\u001B[0m     \u001B[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001B[39;00m\n\u001B[0;32m    512\u001B[0m     \u001B[38;5;66;03m# ctx._wrap_socket()\u001B[39;00m\n\u001B[1;32m--> 513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msslsocket_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    514\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_side\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_side\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Python310\\lib\\ssl.py:1071\u001B[0m, in \u001B[0;36mSSLSocket._create\u001B[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001B[0m\n\u001B[0;32m   1070\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1071\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1072\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mOSError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n",
      "File \u001B[1;32mD:\\Python310\\lib\\ssl.py:1342\u001B[0m, in \u001B[0;36mSSLSocket.do_handshake\u001B[1;34m(self, block)\u001B[0m\n\u001B[0;32m   1341\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msettimeout(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m-> 1342\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1343\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[1;31mSSLEOFError\u001B[0m: EOF occurred in violation of protocol (_ssl.c:997)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\requests\\adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[1;32m--> 489\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[0;32m    503\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[0;32m    785\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[1;32m--> 787\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m    789\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    790\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001B[0m, in \u001B[0;36mRetry.increment\u001B[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[0;32m    591\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_retry\u001B[38;5;241m.\u001B[39mis_exhausted():\n\u001B[1;32m--> 592\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause))\n\u001B[0;32m    594\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
      "\u001B[1;31mMaxRetryError\u001B[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-chinese/resolve/main/tokenizer_config.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mSSLError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [61]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BertTokenizer, BertForSequenceClassification, AdamW\n\u001B[1;32m----> 3\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mBertTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbert-base-chinese\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mC:\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mUsers\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m99480\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43m.cache\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mhuggingface\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mhub\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m tokenizer\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1760\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1758\u001B[0m             resolved_vocab_files[file_id] \u001B[38;5;241m=\u001B[39m download_url(file_path, proxies\u001B[38;5;241m=\u001B[39mproxies)\n\u001B[0;32m   1759\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1760\u001B[0m         resolved_vocab_files[file_id] \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1761\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1762\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1763\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1764\u001B[0m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1765\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1766\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1767\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1768\u001B[0m \u001B[43m            \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1769\u001B[0m \u001B[43m            \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1770\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1771\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1772\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_missing_entries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1773\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_connection_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1774\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1775\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1776\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_vocab_files[file_id], commit_hash)\n\u001B[0;32m   1778\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(unresolved_files) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:409\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[0;32m    406\u001B[0m user_agent \u001B[38;5;241m=\u001B[39m http_user_agent(user_agent)\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    408\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[1;32m--> 409\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    421\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    423\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError:\n\u001B[0;32m    424\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m    425\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a local folder and is not a valid model identifier \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    426\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlisted on \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/models\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf this is a private repository, make sure to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    427\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    428\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    429\u001B[0m     )\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:124\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[0;32m    120\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(\n\u001B[0;32m    121\u001B[0m         fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs\n\u001B[0;32m    122\u001B[0m     )\n\u001B[1;32m--> 124\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1242\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001B[0m\n\u001B[0;32m   1239\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m temp_file_manager() \u001B[38;5;28;01mas\u001B[39;00m temp_file:\n\u001B[0;32m   1240\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdownloading \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, temp_file\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m-> 1242\u001B[0m     \u001B[43mhttp_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1243\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemp_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1246\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1248\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1250\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstoring \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m in cache at \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, blob_path)\n\u001B[0;32m   1251\u001B[0m _chmod_and_replace(temp_file\u001B[38;5;241m.\u001B[39mname, blob_path)\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:475\u001B[0m, in \u001B[0;36mhttp_get\u001B[1;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries)\u001B[0m\n\u001B[0;32m    473\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resume_size \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    474\u001B[0m     headers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRange\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbytes=\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (resume_size,)\n\u001B[1;32m--> 475\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43m_request_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    481\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    483\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    484\u001B[0m hf_raise_for_status(r)\n\u001B[0;32m    485\u001B[0m content_length \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Length\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:438\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[1;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001B[0m\n\u001B[0;32m    435\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n\u001B[0;32m    437\u001B[0m \u001B[38;5;66;03m# 3. Exponential backoff\u001B[39;00m\n\u001B[1;32m--> 438\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m http_backoff(\n\u001B[0;32m    439\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[0;32m    440\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m    441\u001B[0m     max_retries\u001B[38;5;241m=\u001B[39mmax_retries,\n\u001B[0;32m    442\u001B[0m     base_wait_time\u001B[38;5;241m=\u001B[39mbase_wait_time,\n\u001B[0;32m    443\u001B[0m     max_wait_time\u001B[38;5;241m=\u001B[39mmax_wait_time,\n\u001B[0;32m    444\u001B[0m     retry_on_exceptions\u001B[38;5;241m=\u001B[39m(ConnectTimeout, ProxyError),\n\u001B[0;32m    445\u001B[0m     retry_on_status_codes\u001B[38;5;241m=\u001B[39m(),\n\u001B[0;32m    446\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[0;32m    448\u001B[0m )\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:129\u001B[0m, in \u001B[0;36mhttp_backoff\u001B[1;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001B[0m\n\u001B[0;32m    126\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mseek(io_obj_initial_pos)\n\u001B[0;32m    128\u001B[0m \u001B[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001B[39;00m\n\u001B[1;32m--> 129\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m retry_on_status_codes:\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m session\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\requests\\sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[0;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[0;32m    585\u001B[0m }\n\u001B[0;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[1;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\requests\\sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[1;34m(self, request, **kwargs)\u001B[0m\n\u001B[0;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[0;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[0;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[1;32mD:\\Python310\\lib\\site-packages\\requests\\adapters.py:563\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[0;32m    559\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ProxyError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[0;32m    561\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, _SSLError):\n\u001B[0;32m    562\u001B[0m         \u001B[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001B[39;00m\n\u001B[1;32m--> 563\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m SSLError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[0;32m    565\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[0;32m    567\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ClosedPoolError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mSSLError\u001B[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-chinese/resolve/main/tokenizer_config.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:997)')))"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', cache_dir='C:\\\\Users\\99480\\.cache\\huggingface\\hub')\n",
    "tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
